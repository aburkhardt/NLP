{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM classifier\n",
    "\n",
    "This notebook trains a Support Vector Machine (with a linear kernel) to identify relevant tweets (POS).\n",
    "\n",
    "We use scikit-learn's implementation of SVM and its cross validation tools. http://scikit-learn.org/\n",
    "\n",
    "## Installation\n",
    "\n",
    "To install all of the python dependencies for this notbook in a virtual environment:\n",
    "\n",
    "```bash\n",
    "# create environment in directory named 'venv'\n",
    "python -m venv venv\n",
    "# or:\n",
    "# virtualenv venv\n",
    "\n",
    "# activate environment\n",
    "source venv/bin/activate\n",
    "\n",
    "# install dependencies\n",
    "pip3 install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from class_utils import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "iteration=\"iter3a\"\n",
    "#model_filename = \"models/best_svc_{}.pickle\".format(iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data sets\n",
    "\n",
    "Here we parse data from our training files, and then randomly select a portion to be held out for evaluation. The training set is used to both train the SVM classifier and select parameters using k-fold cross validation.\n",
    "\n",
    "The `parse_training_data()` function is provided in the external `class_utils.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse data from files\n",
    "classes = ['NEG', 'POS']\n",
    "docs, targets = parse_training_data(['NEG-{}.txt'.format(iteration), 'POS-{}.txt'.format(iteration)], classes)\n",
    "\n",
    "# convert the targets array of strings to binary labels (0=NEG, 1=POS)\n",
    "lb = LabelBinarizer(sparse_output=False)\n",
    "lb.fit(classes)\n",
    "bin_targets = lb.transform(targets).ravel()\n",
    "\n",
    "# split data set into to training and evaluation sets\n",
    "# X_test/y_test are held out and not used during the\n",
    "# k-fold training and parameter search below\n",
    "#\n",
    "# The percentage of samples to hod out is determined by the `test_size`\n",
    "# parameter\n",
    "# for this iter2, the holdout is only going to be 10% \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    docs, bin_targets, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create sklearn pipeline\n",
    "\n",
    "Here we setup a scikit-learn pipeline to create vectors from our training sample vocabulary (`CountVectorizer`), normalize words based on frequency (`TfidfTransformer`), and train a SVM classifier (`SVC`). http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    "We evaluate parameters based on th `fscore_prec` which is a weighted fscore which favors precision (beta < 1). We also calculate accuracy, precision, recall, and f1 scores for each of the k-fold training sessions.\n",
    "\n",
    "Using a pipeline makes it easy to search a range of hyperparameters using sklearn's `GridSearchCV`. http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pl = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SVC(kernel='linear')),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'vect__preprocessor': [normalize_tweet],\n",
    "    'vect__max_df': np.linspace(0.3, 1.0, 10),\n",
    "    'vect__tokenizer': [casual_tokenize, word_tokenize, None],\n",
    "    #'vect__max_features': [None, 5000, 10000, 50000],\n",
    "    'vect__stop_words': [None, 'english'], # [None, 'english'],\n",
    "    'vect__ngram_range': [(1,3)],  # largest n-gram\n",
    "    #'tfidf__use_idf':[True, False],# (True, False),\n",
    "    #'clf__C': [1, .01, .5, 1, 1.5, 5, 10, 100],\n",
    "   # 'clf__class_weight': [None, 'balanced', {0:1, 1:2}, {0:2, 1:1}],\n",
    "}\n",
    "\n",
    "# define the scores we want to calcualte during each k-fold training\n",
    "fscore_prec = make_scorer(fbeta_score, beta=3)\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'fscore_prec': fscore_prec\n",
    "}\n",
    "\n",
    "# create the GridSearchCV object.\n",
    "# by setting refit='fscore_prec', the model which maximizes that score\n",
    "# will be selected and retrained on all training data.\n",
    "svc_search = GridSearchCV(svc_pl, parameters, n_jobs=-1, verbose=1, scoring=scoring, refit='fscore_prec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...,\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__preprocessor': [<function normalize_tweet at 0x1116dc730>], 'vect__max_df': array([0.3    , 0.37778, 0.45556, 0.53333, 0.61111, 0.68889, 0.76667,\n",
       "       0.84444, 0.92222, 1.     ]), 'vect__tokenizer': [<function casual_tokenize at 0x11457abf8>, <function word_tokenize at 0x1146038c8>, None], 'vect__stop_words': [None, 'english'], 'vect__ngram_range': [(1, 3)]},\n",
       "       pre_dispatch='2*n_jobs', refit='fscore_prec',\n",
       "       return_train_score='warn',\n",
       "       scoring={'accuracy': 'accuracy', 'precision': 'precision', 'recall': 'recall', 'f1': 'f1', 'fscore_prec': make_scorer(fbeta_score, beta=3)},\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we do the actual training\n",
    "# Can take several minutes depending on the range of parameters given\n",
    "# int he parameters dict above\n",
    "svc_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vect__max_df': 0.6111111111111112,\n",
       " 'vect__ngram_range': (1, 3),\n",
       " 'vect__preprocessor': <function class_utils.normalize_tweet(item)>,\n",
       " 'vect__stop_words': 'english',\n",
       " 'vect__tokenizer': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The parameters selected by the grid search\n",
    "svc_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.818\n",
      "precision: 0.812\n",
      "recall: 0.527\n",
      "f1: 0.635\n",
      "fscore_prec: 0.546\n"
     ]
    }
   ],
   "source": [
    "# print the average scores over the k training folds\n",
    "fields = ['accuracy', 'precision', 'recall', 'f1', 'fscore_prec']\n",
    "\n",
    "for f in fields:\n",
    "    score = svc_search.cv_results_[\"mean_test_%s\" % f][svc_search.best_index_]\n",
    "    print(\"%s: %.3f\" % (f, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We check how it works by running the best classifier from the grid search on our held out set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model from grid search we ran in previous section\n",
    "best_model = svc_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use model to predict held out set (X_test) and print score table\n",
    "# Note that in binary classification, accuracy is the same as the\n",
    "# [mico averaged recall reported in the table\n",
    "predictions = best_model.predict(X_test)\n",
    "print(classification_report(y_test, predictions, target_names=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persist model\n",
    "\n",
    "Take our best model, retrain it on entire training dataset (including the held out set used for evaluation above), and persist it to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on all data\n",
    "best_model.fit(docs, bin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
